{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Meghana Kambhampati\n",
        "\n",
        "MXK190048\n",
        "\n",
        "CS4395\n",
        "\n",
        "Portfolio 3: WordNet\n",
        "\n",
        "This program demonstrates and explains some of the features of WordNet and SentiWordNet. It details some of the tools and algorithms within WordNet as well as applications for them. "
      ],
      "metadata": {
        "id": "pfNB1bINFTUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "."
      ],
      "metadata": {
        "id": "vjrNqmyC6dnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordNet is a collection of glosses and usage examples for words. It is used for natural language processing. WordNet organizes words by parts of speech in hierarchies. Similar words are grouped together in synsets. "
      ],
      "metadata": {
        "id": "5Nl2Z63VIWjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import math\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('sentiwordnet')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('webtext')\n",
        "nltk.download('treebank')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('book')\n",
        "from nltk.book import * \n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk.wsd import lesk\n",
        "from nltk.corpus import wordnet as wn\n"
      ],
      "metadata": {
        "id": "P_3hHSGBFNnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets('plant')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svw0cjr4bX3B",
        "outputId": "1e38f727-47bd-42d6-f6ed-6391a4ae1517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('plant.n.01'),\n",
              " Synset('plant.n.02'),\n",
              " Synset('plant.n.03'),\n",
              " Synset('plant.n.04'),\n",
              " Synset('plant.v.01'),\n",
              " Synset('implant.v.01'),\n",
              " Synset('establish.v.02'),\n",
              " Synset('plant.v.04'),\n",
              " Synset('plant.v.05'),\n",
              " Synset('plant.v.06')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('definition:', wn.synset('plant.n.04').definition())\n",
        "print('usage:', wn.synset('plant.n.04').examples())\n",
        "print('lemmas:', wn.synset('plant.n.04').lemmas())\n",
        "\n",
        "# closure\n",
        "print('\\nhierarchy:')\n",
        "plant = wn.synset('plant.n.04')\n",
        "hyper = lambda s: s.hypernyms()\n",
        "list(plant.closure(hyper))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCVLC_Jdbjbl",
        "outputId": "5769bee8-d000-45d7-d5d0-e9904d775dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "definition: something planted secretly for discovery by another\n",
            "usage: ['the police used a plant to trick the thieves', 'he claimed that the evidence against him was a plant']\n",
            "lemmas: [Lemma('plant.n.04.plant')]\n",
            "\n",
            "hierarchy:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('contrivance.n.03'),\n",
              " Synset('scheme.n.01'),\n",
              " Synset('plan_of_action.n.01'),\n",
              " Synset('plan.n.01'),\n",
              " Synset('idea.n.01'),\n",
              " Synset('content.n.05'),\n",
              " Synset('cognition.n.01'),\n",
              " Synset('psychological_feature.n.01'),\n",
              " Synset('abstraction.n.06'),\n",
              " Synset('entity.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In WordNet, nouns are organized like a tree or hierarchy. There are several \"base\" nouns that then get more and more specific as you go down. Nouns have special associations like hypernyms (more general category of word), hyponyms (specific types of given word), holonyms (whole-of relationship), meronyms (part-of relationship), and antonyms (opposite meaning). These relationships make up the larger WordNet hierarchy. "
      ],
      "metadata": {
        "id": "PptGJKCJGmZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('hypernyms:', plant.hypernyms())\n",
        "print('hyponyms:', plant.hyponyms())\n",
        "print('meronyms:', plant.part_meronyms(), plant.substance_meronyms())\n",
        "print('holonyms:', plant.part_holonyms(), plant.substance_holonyms())\n",
        "plant = wn.synsets('plant', pos=wn.NOUN)[0].lemmas()[0]\n",
        "print('antonyms:', plant.antonyms())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRaIplEKKmdV",
        "outputId": "380746a9-c47b-49ef-de72-56fbd39f75c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hypernyms: [Synset('contrivance.n.03')]\n",
            "hyponyms: []\n",
            "meronyms: [] []\n",
            "holonyms: [] []\n",
            "antonyms: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets('bake')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmP27d51a1g8",
        "outputId": "94a00ca9-77ef-4965-ea6d-3b3523650108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('bake.v.01'),\n",
              " Synset('bake.v.02'),\n",
              " Synset('broil.v.02'),\n",
              " Synset('bake.v.04')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('definition:', wn.synset('bake.v.01').definition())\n",
        "print('usage:', wn.synset('bake.v.01').examples())\n",
        "print('lemmas:', wn.synset('bake.v.01').lemmas())\n",
        "\n",
        "# closure\n",
        "print('\\nhierarchy:')\n",
        "bake = wn.synset('bake.v.01')\n",
        "hyper = lambda s: s.hypernyms()\n",
        "list(bake.closure(hyper))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEIbNpXlbAhF",
        "outputId": "c0a6498c-efc7-42dd-e1b6-97e6c57714b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "definition: cook and make edible by putting in a hot oven\n",
            "usage: ['bake the potatoes']\n",
            "lemmas: [Lemma('bake.v.01.bake')]\n",
            "\n",
            "hierarchy:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('cook.v.03'), Synset('change_integrity.v.01'), Synset('change.v.02')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verbs are stored similarly to nouns in WordNet. There is a hierarchy with more specific types of actions (troponyms) near the bottom and more general verb events near the top. "
      ],
      "metadata": {
        "id": "MjLQDX8lbVOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(wn.morphy('baking', wn.VERB))\n",
        "print(wn.morphy('baked'))\n",
        "print(wn.morphy('bakes'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSl7DMfDbXJY",
        "outputId": "9654a7ef-8b70-4aed-9822-85743ee39ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bake\n",
            "bake\n",
            "bake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(wn.synsets('bake'))\n",
        "print(wn.synsets('cook'))\n",
        "\n",
        "bake = wn.synset('bake.v.01')\n",
        "cook = wn.synset('cook.v.01')\n",
        "\n",
        "# Wu-Palmer\n",
        "print('\\nWu-Palmer similarity metric:')\n",
        "print(wn.wup_similarity(bake, cook))\n",
        "\n",
        "# Lesk\n",
        "print('\\nLesk algorithm:')\n",
        "sent = ['The', 'cook', 'bakes', 'cookies', '.']\n",
        "print(sent)\n",
        "print(lesk(sent, 'cook'))\n",
        "print('fudge.v.01:', wn.synset('fudge.v.01').definition())\n",
        "print(lesk(sent, 'cook', 'n'))\n",
        "print('cook.n.02:', wn.synset('cook.n.02').definition())\n",
        "print(lesk(sent, 'bakes'))\n",
        "print('bake.v.01:', wn.synset('bake.v.01').definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDRBrBC9hx2L",
        "outputId": "9e70be95-f5c4-43ed-a69a-29b45eac3b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('bake.v.01'), Synset('bake.v.02'), Synset('broil.v.02'), Synset('bake.v.04')]\n",
            "[Synset('cook.n.01'), Synset('cook.n.02'), Synset('cook.v.01'), Synset('cook.v.02'), Synset('cook.v.03'), Synset('fudge.v.01'), Synset('cook.v.05')]\n",
            "\n",
            "Wu-Palmer similarity metric:\n",
            "0.2222222222222222\n",
            "\n",
            "Lesk algorithm:\n",
            "['The', 'cook', 'bakes', 'cookies', '.']\n",
            "Synset('fudge.v.01')\n",
            "fudge.v.01: tamper, with the purpose of deception\n",
            "Synset('cook.n.02')\n",
            "cook.n.02: English navigator who claimed the east coast of Australia for Britain and discovered several Pacific islands (1728-1779)\n",
            "Synset('bake.v.01')\n",
            "bake.v.01: cook and make edible by putting in a hot oven\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The words 'cook' and 'bake' are not as similar as I would have guessed, since they have a lot of use case overlap. The Lesk algorithm misidentified the form of 'cook' in the sentence even when the part of speech was specified. The algorithm got the form of 'bake'' correct without any modifications."
      ],
      "metadata": {
        "id": "e9-nIf2FtQYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SentiWordNet is an extension of WordNet. It can assign positivity, negativity, and objectivity sentiment points to a word. This can be used to determine the sentiment or tone of a sentence based on the words and punctuation used. For example, SentiWordNet can analyze the sentence 'that movie was great!' and determine wheter it is a positive or negative sentence. "
      ],
      "metadata": {
        "id": "EYul_dLCtRC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "senti_list = list(swn.senti_synsets('fantastic')) \n",
        "for item in senti_list:\n",
        "    print(item)\n",
        "\n",
        "sent1 = 'This is the worst day of my life'\n",
        "print('\\n' + sent1)\n",
        "tokens = sent1.split()\n",
        "for token in tokens:\n",
        "    syn_list = list(swn.senti_synsets(token))\n",
        "    if syn_list:\n",
        "        syn = syn_list[0]\n",
        "        print(syn)\n",
        "\n",
        "sent2 = 'This is the best day of my life'\n",
        "print('\\n' + sent2)\n",
        "tokens = sent2.split()\n",
        "for token in tokens:\n",
        "    syn_list = list(swn.senti_synsets(token))\n",
        "    if syn_list:\n",
        "        syn = syn_list[0]\n",
        "        print(syn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbxV70A2ybY3",
        "outputId": "bfaaf31c-6b9b-4c6c-aa27-3c564a8e8462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<antic.s.01: PosScore=0.375 NegScore=0.0>\n",
            "<fantastic.s.02: PosScore=0.75 NegScore=0.0>\n",
            "<fantastic.s.03: PosScore=0.375 NegScore=0.375>\n",
            "<fantastic.s.04: PosScore=0.0 NegScore=0.625>\n",
            "<fantastic.s.05: PosScore=0.375 NegScore=0.375>\n",
            "\n",
            "This is the worst day of my life\n",
            "<be.v.01: PosScore=0.25 NegScore=0.125>\n",
            "<worst.n.01: PosScore=0.0 NegScore=1.0>\n",
            "<day.n.01: PosScore=0.0 NegScore=0.0>\n",
            "<life.n.01: PosScore=0.0 NegScore=0.0>\n",
            "\n",
            "This is the best day of my life\n",
            "<be.v.01: PosScore=0.25 NegScore=0.125>\n",
            "<best.n.01: PosScore=0.25 NegScore=0.0>\n",
            "<day.n.01: PosScore=0.0 NegScore=0.0>\n",
            "<life.n.01: PosScore=0.0 NegScore=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"emotionally charged\" words like 'best' or 'worst' have the largest positive or negative scores. More objective words like 'be' and 'life' have a smaller impact on the overall sentiment of a sentence. This information is useful to have when trying to determine the tone or emotion behind a group of text. "
      ],
      "metadata": {
        "id": "3deiZHFFGpbL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A collocation is a series of words that appear together frequently. They often combine to create a new meaning. If one of the words is changed, the meaning is no longer the same."
      ],
      "metadata": {
        "id": "U7cyZNELGqd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text4.collocations()\n",
        "\n",
        "text = ' '.join(text4.tokens)\n",
        "vocab = len(set(text4))\n",
        "hg = text.count('General Government')/vocab\n",
        "print(\"\\np(General Government) = \", hg )\n",
        "h = text.count('General')/vocab\n",
        "print(\"p(General) = \", h)\n",
        "g = text.count('Government')/vocab\n",
        "print('p(Government) = ', g)\n",
        "pmi = math.log2(hg / (h * g))\n",
        "print('pmi = ', pmi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a6SdW-QGuKB",
        "outputId": "28e047ac-11f3-4499-9645-ea774fe6d994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "United States; fellow citizens; years ago; four years; Federal\n",
            "Government; General Government; American people; Vice President; God\n",
            "bless; Chief Justice; one another; fellow Americans; Old World;\n",
            "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
            "tribes; public debt; foreign nations\n",
            "\n",
            "p(General Government) =  0.002394014962593516\n",
            "p(General) =  0.002394014962593516\n",
            "p(Government) =  0.03371571072319202\n",
            "pmi =  4.890435179947461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pmi of \"General Government\" is a positive number. The probability that the words \"General\" and \"Government\" will appear together is higher than chance. This means that \"General Government\" is likely to be a collocation.  "
      ],
      "metadata": {
        "id": "aRvF6yTEGw1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "."
      ],
      "metadata": {
        "id": "PGVgJ9G4kx8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordNet and SentiWordNet are useful tools that can be applied in many ways. They are used in NLP to analyze words and and their contexts. "
      ],
      "metadata": {
        "id": "mTIOZppvj0yJ"
      }
    }
  ]
}